@book{bruce2017,
  title = {Practical {{Statistics}} for {{Data Scientists}}: 50 {{Essential Concepts}}},
  shorttitle = {Practical {{Statistics}} for {{Data Scientists}}},
  author = {Bruce, Peter and Bruce, Andrew},
  year = {2017},
  month = may,
  publisher = {{"O'Reilly Media, Inc."}},
  abstract = {Statistical methods are a key part of of data science, yet very few data scientists have any formal statistics training. Courses and books on basic statistics rarely cover the topic from a data science perspective. This practical guide explains how to apply various statistical methods to data science, tells you how to avoid their misuse, and gives you advice on what's important and what's not.Many data science resources incorporate statistical methods but lack a deeper statistical perspective. If you're familiar with the R programming language, and have some exposure to statistics, this quick reference bridges the gap in an accessible, readable format.With this book, you'll learn:Why exploratory data analysis is a key preliminary step in data scienceHow random sampling can reduce bias and yield a higher quality dataset, even with big dataHow the principles of experimental design yield definitive answers to questionsHow to use regression to estimate outcomes and detect anomaliesKey classification techniques for predicting which categories a record belongs toStatistical machine learning methods that ``learn'' from dataUnsupervised learning methods for extracting meaning from unlabeled data},
  googlebooks = {ldPTDgAAQBAJ},
  isbn = {978-1-4919-5291-7},
  langid = {english},
  keywords = {Computers / Data Science / Data Warehousing,Computers / Data Science / General,Computers / Database Administration \& Management}
}

@inproceedings{chen2016,
  title = {{{XGBoost}}: {{A Scalable Tree Boosting System}}},
  shorttitle = {{{XGBoost}}},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Chen, Tianqi and Guestrin, Carlos},
  year = {2016},
  month = aug,
  series = {{{KDD}} '16},
  pages = {785--794},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2939672.2939785},
  url = {https://dl.acm.org/doi/10.1145/2939672.2939785},
  urldate = {2023-09-30},
  abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
  isbn = {978-1-4503-4232-2},
  keywords = {large-scale machine learning},
  file = {/Users/robwiederstein/Zotero/storage/E924WJD3/Chen and Guestrin - 2016 - XGBoost A Scalable Tree Boosting System.pdf}
}

@article{chohlas-wood2023,
  title = {Designing Equitable Algorithms},
  author = {{Chohlas-Wood}, Alex and Coots, Madison and Goel, Sharad and Nyarko, Julian},
  year = {2023},
  month = jul,
  journal = {Nature Computational Science},
  volume = {3},
  number = {7},
  pages = {601--610},
  publisher = {{Nature Publishing Group}},
  issn = {2662-8457},
  doi = {10.1038/s43588-023-00485-4},
  url = {https://www.nature.com/articles/s43588-023-00485-4},
  urldate = {2023-09-30},
  abstract = {Predictive algorithms are now commonly used to distribute society's resources and sanctions. But these algorithms can entrench and exacerbate inequities. To guard against this possibility, many have suggested that algorithms be subject to formal fairness constraints. Here we argue, however, that popular constraints\textemdash while intuitively appealing\textemdash often worsen outcomes for individuals in marginalized groups, and can even leave all groups worse off. We outline a more holistic path forward for improving the equity of algorithmically guided decisions.},
  copyright = {2023 Springer Nature America, Inc.},
  langid = {english},
  keywords = {Computer science,Ethics,Interdisciplinary studies},
  file = {/Users/robwiederstein/Zotero/storage/8NPZQIU7/Chohlas-Wood et al. - 2023 - Designing equitable algorithms.pdf}
}

@article{johnson2023,
  title = {Data-{{Centric AI}} for {{Healthcare Fraud Detection}}},
  author = {Johnson, Justin M. and Khoshgoftaar, Taghi M.},
  year = {2023},
  month = may,
  journal = {SN Computer Science},
  volume = {4},
  number = {4},
  pages = {389},
  issn = {2661-8907},
  doi = {10.1007/s42979-023-01809-x},
  url = {https://doi.org/10.1007/s42979-023-01809-x},
  urldate = {2023-09-15},
  abstract = {Automated methods for detecting fraudulent healthcare providers have the potential to save billions of dollars in healthcare costs and improve the overall quality of patient care. This study presents a data-centric approach to improve healthcare fraud classification performance and reliability using Medicare claims data. Publicly available data from the Centers for Medicare \& Medicaid Services (CMS) are used to construct nine large-scale labeled data sets for supervised learning. First, we leverage CMS data to curate the 2013\textendash 2019 Part B, Part D, and Durable Medical Equipment, Prosthetics, Orthotics, and Supplies (DMEPOS) Medicare fraud classification data sets. We provide a review of each data set and data preparation techniques to create Medicare data sets for supervised learning and we propose an improved data labeling process. Next, we enrich the original Medicare fraud data sets with up to 58 new provider summary features. Finally, we address a common model evaluation pitfall and propose an adjusted cross-validation technique that mitigates target leakage to provide reliable evaluation results. Each data set is evaluated on the Medicare fraud classification task using extreme gradient boosting and random forest learners, multiple complementary performance metrics, and 95\% confidence intervals. Results show that the new enriched data sets consistently outperform the original Medicare data sets that are currently used in related works. Our results encourage the data-centric machine learning workflow and provide a strong foundation for data understanding and preparation techniques for machine learning applications in healthcare fraud.},
  langid = {english},
  keywords = {Big data,Data labeling,Data preparation,Data quality,Fraud detection,Healthcare},
  file = {/Users/robwiederstein/Zotero/storage/DC8Q3UNA/Johnson and Khoshgoftaar - 2023 - Data-Centric AI for Healthcare Fraud Detection.pdf}
}

@article{starr2014,
  title = {Evidence-{{Based Sentencing}} and the {{Scientific Rationalization}} of {{Discrimination}}},
  author = {Starr, Sonja B.},
  year = {2014},
  journal = {Stanford Law Review},
  volume = {66},
  number = {4},
  eprint = {24246717},
  eprinttype = {jstor},
  pages = {803--872},
  publisher = {{Stanford Law Review}},
  issn = {0038-9765},
  url = {https://www.jstor.org/stable/24246717},
  urldate = {2023-09-30},
  abstract = {This Article critiques, on legal and empirical grounds, the growing trend of basing criminal sentences on actuarial recidivism risk prediction instruments that include demographic and socioeconomic variables. largue that this practice violates the Equal Protection Clause and is bad policy: an explicit embrace of otherwise-condemned discrimination, sanitized by scientific language. To demonstrate that this practice raises serious constitutional concerns, I comprehensively review the relevant case law, much of which has been ignored by existing literature. To demonstrate that the policy is not justified by countervailing state interests, I review the empirical evidence underlying the instruments. I show that they provide wildly imprecise individual risk predictions, that there is no compelling evidence that they outperform judges' informal predictions, that less discriminatory alternatives would likely perform as well, and that the instruments do not even address the right question: the effect of a given sentencing decision on recidivism risk. Finally, I also present new empirical evidence, based on a randomized experiment using fictional cases, suggesting that these instruments should not be expected merely to substitute actuarial predictions for less scientific risk assessments but instead to increase the weight given to recidivism risk versus other sentencing considerations.},
  file = {/Users/robwiederstein/Zotero/storage/X9WSADZG/Starr - 2014 - Evidence-Based Sentencing and the Scientific Ratio.pdf}
}

@article{tay2023,
  title = {Elastic {{Net Regularization Paths}} for {{All Generalized Linear Models}}},
  author = {Tay, J. Kenneth and Narasimhan, Balasubramanian and Hastie, Trevor},
  year = {2023},
  month = mar,
  journal = {Journal of Statistical Software},
  volume = {106},
  pages = {1--31},
  issn = {1548-7660},
  doi = {10.18637/jss.v106.i01},
  url = {https://doi.org/10.18637/jss.v106.i01},
  urldate = {2023-09-30},
  abstract = {The lasso and elastic net are popular regularized regression models for supervised learning. Friedman, Hastie, and Tibshirani (2010) introduced a computationally efficient algorithm for computing the elastic net regularization path for ordinary least squares regression, logistic regression and multinomial logistic regression, while Simon, Friedman, Hastie, and Tibshirani (2011) extended this work to Cox models for right-censored data. We further extend the reach of the elastic net-regularized regression to all generalized linear model families, Cox models with (start, stop] data and strata, and a simplified version of the relaxed lasso. We also discuss convenient utility functions for measuring the performance of these fitted models.},
  copyright = {Copyright (c) 2023 J. Kenneth Tay, Balasubramanian Narasimhan, Trevor Hastie},
  langid = {english},
  keywords = {coordinate descent,Cox model,elastic net,generalized linear models,l1 penalty,lasso,regularization path,survival},
  file = {/Users/robwiederstein/Zotero/storage/DVTHXDHH/Tay et al. - 2023 - Elastic Net Regularization Paths for All Generaliz.pdf}
}

@article{wright2017,
  title = {Ranger: {{A Fast Implementation}} of {{Random Forests}} for {{High Dimensional Data}} in {{C}}++ and {{R}}},
  shorttitle = {Ranger},
  author = {Wright, Marvin N. and Ziegler, Andreas},
  year = {2017},
  month = mar,
  journal = {Journal of Statistical Software},
  volume = {77},
  pages = {1--17},
  issn = {1548-7660},
  doi = {10.18637/jss.v077.i01},
  url = {https://doi.org/10.18637/jss.v077.i01},
  urldate = {2023-09-30},
  abstract = {We introduce the C++ application and R package ranger. The software is a fast implementation of random forests for high dimensional data. Ensembles of classification, regression and survival trees are supported. We describe the implementation, provide examples, validate the package with a reference implementation, and compare runtime and memory usage with other implementations. The new software proves to scale best with the number of features, samples, trees, and features tried for splitting. Finally, we show that ranger is the fastest and most memory efficient implementation of random forests to analyze data on the scale of a genome-wide association study.},
  copyright = {Copyright (c) 2017 Marvin N. Wright, Andreas Ziegler},
  langid = {english},
  keywords = {C,classification,machine learning,R,random forests,Rcpp,recursive partitioning,survival analysis},
  file = {/Users/robwiederstein/Zotero/storage/ZUZTBRBT/Wright and Ziegler - 2017 - ranger A Fast Implementation of Random Forests fo.pdf}
}

@article{yang2020,
  title = {Equal {{Protection Under Algorithms}}: {{A New Statistical}} and {{Legal Framework}}},
  shorttitle = {Equal {{Protection Under Algorithms}}},
  author = {Yang, Crystal and Dobbie, Will},
  year = {2020},
  month = nov,
  journal = {Michigan Law Review},
  volume = {119},
  number = {2},
  pages = {291--396},
  issn = {0026-2234},
  doi = {10.36644/mlr.119.2.equal},
  url = {https://repository.law.umich.edu/mlr/vol119/iss2/3},
  file = {/Users/robwiederstein/Zotero/storage/IDDDCYUJ/Yang and Dobbie - 2020 - Equal Protection Under Algorithms A New Statistic.pdf;/Users/robwiederstein/Zotero/storage/JWE7LVHU/3.html}
}
